{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import FileVideoStream\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')    \n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.app_utils import FPS, WebcamVideoStream\n",
    "from multiprocessing import Queue, Pool\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "PATH_TO_MODEL = \"../models/faster_rcnn_inception_v2_coco_2017_11_08/frozen_inference_graph.pb\"\n",
    "PATH_TO_LABELS = \"../object_detection/data/mscoco_label_map.pbtxt\"\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n",
    "                                                           use_display_name = True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection sections ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_np, sess, detection_graph):\n",
    "    t_detect = time.time()\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "        [boxes, scores, classes, num_detections],\n",
    "        feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    t_elapsed = time.time() - t_detect\n",
    "    print('[INFO] frame detection time: {:.2f}'.format(t_elapsed))\n",
    "    \n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=2)\n",
    "    return image_np, t_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(input_q, output_q):\n",
    "    # Load a (frozen) Tensorflow model into memory.\n",
    "    print(\"[INFO] loading TF model...\")\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "    print(\"[INFO] model loaded...\")\n",
    "    t_acc = 0\n",
    "    while True:\n",
    "        frame = input_q.get()\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        im, t_elapsed = detect_objects(frame_rgb, sess, detection_graph)\n",
    "        t_acc = t_acc + t_elapsed\n",
    "        print('[INFO] accumulated detection time: {:.2f}'.format(t_acc))\n",
    "        output_q.put(im)\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1048, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1012, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 223, in findsource\n",
      "    pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n",
      "  File \"/usr/lib/python2.7/re.py\", line 194, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/usr/lib/python2.7/re.py\", line 249, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/usr/lib/python2.7/sre_compile.py\", line 572, in compile\n",
      "    p = sre_parse.parse(p, flags)\n",
      "  File \"/usr/lib/python2.7/sre_parse.py\", line 716, in parse\n",
      "    p = _parse_sub(source, pattern, 0)\n",
      "  File \"/usr/lib/python2.7/sre_parse.py\", line 324, in _parse_sub\n",
      "    itemsappend(_parse(source, state))\n",
      "  File \"/usr/lib/python2.7/sre_parse.py\", line 413, in _parse\n",
      "    this = sourceget()\n",
      "  File \"/usr/lib/python2.7/sre_parse.py\", line 214, in get\n",
      "    self.__next()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 97, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"<ipython-input-6-137bd9be9acd>\", line 18, in worker\n",
      "    im, t_elapsed = detect_objects(frame_rgb, sess, detection_graph)\n",
      "  File \"<ipython-input-5-6c8da66803e2>\", line 19, in detect_objects\n",
      "    feed_dict={image_tensor: image_np_expanded})\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1128, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1329, in _run_fn\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "num_workers = 1\n",
    "num_queue = 5\n",
    "\n",
    "# debugging\n",
    "#logger = multiprocessing.log_to_stderr()\n",
    "#logger.setLevel(multiprocessing.SUBDEBUG)\n",
    "\n",
    "input_q = Queue(maxsize=num_queue)\n",
    "output_q = Queue(maxsize=num_queue)\n",
    "pool = Pool(num_workers, worker, (input_q, output_q))\n",
    "\n",
    "print(\"[INFO] starting video file thread...\")\n",
    "video_capture = FileVideoStream(\"../data/test_video.mp4\").start()\n",
    "\n",
    "time.sleep(1.0)\n",
    "#video_capture = WebcamVideoStream(src=0,width=480,height=360).start()\n",
    "fps = FPS().start()\n",
    "framecnt = 0\n",
    "while video_capture.more(): \n",
    "    clear_output(wait=True)\n",
    "    t = time.time()\n",
    "    \n",
    "    frame = video_capture.read()\n",
    "    framecnt = framecnt + 1\n",
    "    frame = imutils.resize(frame, width=480)\n",
    "    input_q.put(frame)\n",
    "\n",
    "    output_rgb = output_q.get()\n",
    "    #output_rgb = cv2.cvtColor(output_q.get(), cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imshow('Video', output_rgb)\n",
    "    #clear_output(wait=True)\n",
    "    #plt.imshow(output_rgb)\n",
    "    #plt.show()\n",
    "    \n",
    "    #if framecnt % 30 == 0:\n",
    "    #    clear_output(wait=True)\n",
    "    #    plt.figure(figsize=(20, 7))\n",
    "    #    plt.imshow(output_rgb)\n",
    "    #    plt.show()\n",
    "    \n",
    "    fps.update()\n",
    "    print('[INFO] frames processed: {:.2f}'.format(framecnt))\n",
    "    print('[INFO] total frame elapsed time: {:.2f}'.format(time.time() - t))\n",
    "    print('[INFO] queued frames: {:d}'.format(video_capture.Q.qsize()))\n",
    "\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "fps.stop()\n",
    "print('[INFO] elapsed time (total): {:.2f}'.format(fps.elapsed()))\n",
    "print('[INFO] approx. FPS: {:.2f}'.format(fps.fps()))\n",
    "print('[INFO] total frames processed: {:d}'.format(framecnt))\n",
    "\n",
    "pool.terminate()\n",
    "video_capture.stop()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS for detection: 0.03\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 24\n",
      "[INFO] loading TF model...\n"
     ]
    }
   ],
   "source": [
    "print('FPS for detection: {:.2f}'.format(20/797.05))\n",
    "#print('FPS entire processing: {:.2f}'.format(912/fps.elapsed()))\n",
    "#print('Time taken to post-process 31s videofile: {:.2f}s'.format(fps.elapsed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
