{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import FileVideoStream\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')    \n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.app_utils import FPS, WebcamVideoStream\n",
    "from multiprocessing import Queue, Pool\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "PATH_TO_MODEL = \"../models/ssd_mobilenet_v1_coco/frozen_inference_graph.pb\"\n",
    "PATH_TO_LABELS = \"../object_detection/data/mscoco_label_map.pbtxt\"\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n",
    "                                                           use_display_name = True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection sections ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_np, sess, detection_graph):\n",
    "    t_detect = time.time()\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "        [boxes, scores, classes, num_detections],\n",
    "        feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    t_elapsed = time.time() - t_detect\n",
    "    print('[INFO] frame detection time: {:.2f}'.format(t_elapsed))\n",
    "    \n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=2)\n",
    "    return image_np, t_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(input_q, output_q):\n",
    "    # Load a (frozen) Tensorflow model into memory.\n",
    "    print(\"[INFO] loading TF model...\")\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "    print(\"[INFO] model loaded...\")\n",
    "    t_acc = 0\n",
    "    while True:\n",
    "        frame = input_q.get()\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        im, t_elapsed = detect_objects(frame_rgb, sess, detection_graph)\n",
    "        t_acc = t_acc + t_elapsed\n",
    "        print('[INFO] accumulated detection time: {:.2f}'.format(t_acc))\n",
    "        output_q.put(im)\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] frame detection time: 0.32\n",
      "[INFO] accumulated detection time: 233.17\n",
      "[INFO] total frame elapsed time: 0.36\n",
      "[INFO] queued frames: 0\n",
      "[INFO] elapsed time (total): 296.98\n",
      "[INFO] approx. FPS: 3.05\n",
      "[INFO] total frames processed: 907\n"
     ]
    }
   ],
   "source": [
    "num_workers = 1\n",
    "num_queue = 5\n",
    "\n",
    "# debugging\n",
    "#logger = multiprocessing.log_to_stderr()\n",
    "#logger.setLevel(multiprocessing.SUBDEBUG)\n",
    "\n",
    "input_q = Queue(maxsize=num_queue)\n",
    "output_q = Queue(maxsize=num_queue)\n",
    "pool = Pool(num_workers, worker, (input_q, output_q))\n",
    "\n",
    "print(\"[INFO] starting video file thread...\")\n",
    "video_capture = FileVideoStream(\"../data/test_video.mp4\").start()\n",
    "\n",
    "time.sleep(1.0)\n",
    "#video_capture = WebcamVideoStream(src=0,width=480,height=360).start()\n",
    "fps = FPS().start()\n",
    "framecnt = 0\n",
    "while video_capture.more(): \n",
    "    clear_output(wait=True)\n",
    "    t = time.time()\n",
    "    \n",
    "    frame = video_capture.read()\n",
    "    framecnt = framecnt + 1\n",
    "    frame = imutils.resize(frame, width=480)\n",
    "    input_q.put(frame)\n",
    "\n",
    "    output_rgb = output_q.get()\n",
    "    #output_rgb = cv2.cvtColor(output_q.get(), cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imshow('Video', output_rgb)\n",
    "    #clear_output(wait=True)\n",
    "    #plt.imshow(output_rgb)\n",
    "    #plt.show()\n",
    "    \n",
    "    #if framecnt % 30 == 0:\n",
    "    #    clear_output(wait=True)\n",
    "    #    plt.figure(figsize=(20, 7))\n",
    "    #    plt.imshow(output_rgb)\n",
    "    #    plt.show()\n",
    "    \n",
    "    fps.update()\n",
    "    \n",
    "    print('[INFO] total frame elapsed time: {:.2f}'.format(time.time() - t))\n",
    "    print('[INFO] queued frames: {:d}'.format(video_capture.Q.qsize()))\n",
    "\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "fps.stop()\n",
    "print('[INFO] elapsed time (total): {:.2f}'.format(fps.elapsed()))\n",
    "print('[INFO] approx. FPS: {:.2f}'.format(fps.fps()))\n",
    "print('[INFO] total frames processed: {:d}'.format(framecnt))\n",
    "\n",
    "pool.terminate()\n",
    "video_capture.stop()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS for detection: 3.91\n",
      "FPS entire processing: 3.07\n",
      "Time taken to post-process 31s videofile: 296.98s\n"
     ]
    }
   ],
   "source": [
    "print('FPS for detection: {:.2f}'.format(912/233.17))\n",
    "print('FPS entire processing: {:.2f}'.format(912/fps.elapsed()))\n",
    "print('Time taken to post-process 31s videofile: {:.2f}s'.format(fps.elapsed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
