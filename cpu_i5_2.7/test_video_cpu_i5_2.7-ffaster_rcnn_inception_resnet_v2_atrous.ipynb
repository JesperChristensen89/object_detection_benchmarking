{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import FileVideoStream\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')    \n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.app_utils import FPS, WebcamVideoStream\n",
    "from multiprocessing import Queue, Pool\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "PATH_TO_MODEL = \"../models/faster_rcnn_inception_resnet_v2_atrous_coco_2017_11_08/frozen_inference_graph.pb\"\n",
    "PATH_TO_LABELS = \"../object_detection/data/mscoco_label_map.pbtxt\"\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n",
    "                                                           use_display_name = True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection sections ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_objects(image_np, sess, detection_graph):\n",
    "    t_detect = time.time()\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "        [boxes, scores, classes, num_detections],\n",
    "        feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    t_elapsed = time.time() - t_detect\n",
    "    print('[INFO] frame detection time: {:.2f}'.format(t_elapsed))\n",
    "    \n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=2)\n",
    "    return image_np, t_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def worker(input_q, output_q):\n",
    "    # Load a (frozen) Tensorflow model into memory.\n",
    "    print(\"[INFO] loading TF model...\")\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "    print(\"[INFO] model loaded...\")\n",
    "    t_acc = 0\n",
    "    while True:\n",
    "        frame = input_q.get()\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        im, t_elapsed = detect_objects(frame_rgb, sess, detection_graph)\n",
    "        t_acc = t_acc + t_elapsed\n",
    "        print('[INFO] accumulated detection time: {:.2f}'.format(t_acc))\n",
    "        output_q.put(im)\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading TF model...\n",
      "[INFO] starting video file thread...\n",
      "[INFO] model loaded...\n",
      "[INFO] frame detection time: 78.39\n",
      "[INFO] accumulated detection time: 78.39\n",
      "[INFO] total frame elapsed time: 107.67\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 58.57\n",
      "[INFO] accumulated detection time: 136.96\n",
      "[INFO] total frame elapsed time: 58.73\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 58.99\n",
      "[INFO] accumulated detection time: 195.95\n",
      "[INFO] total frame elapsed time: 59.08\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 59.27\n",
      "[INFO] accumulated detection time: 255.23\n",
      "[INFO] total frame elapsed time: 59.35\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 59.73\n",
      "[INFO] accumulated detection time: 314.96\n",
      "[INFO] total frame elapsed time: 59.90\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 57.69\n",
      "[INFO] accumulated detection time: 372.65\n",
      "[INFO] total frame elapsed time: 57.80\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 59.02\n",
      "[INFO] accumulated detection time: 431.67\n",
      "[INFO] total frame elapsed time: 59.12\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 57.82\n",
      "[INFO] accumulated detection time: 489.50\n",
      "[INFO] total frame elapsed time: 57.95\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 58.75\n",
      "[INFO] accumulated detection time: 548.25\n",
      "[INFO] total frame elapsed time: 58.83\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 58.84\n",
      "[INFO] accumulated detection time: 607.09\n",
      "[INFO] total frame elapsed time: 58.94\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 64.14\n",
      "[INFO] accumulated detection time: 671.23\n",
      "[INFO] total frame elapsed time: 64.31\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 66.34\n",
      "[INFO] accumulated detection time: 737.57\n",
      "[INFO] total frame elapsed time: 66.47\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 59.45\n",
      "[INFO] accumulated detection time: 797.03\n",
      "[INFO] total frame elapsed time: 59.53\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 57.98\n",
      "[INFO] accumulated detection time: 855.01\n",
      "[INFO] total frame elapsed time: 58.09\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 60.21\n",
      "[INFO] accumulated detection time: 915.21\n",
      "[INFO] total frame elapsed time: 60.30\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 57.90\n",
      "[INFO] accumulated detection time: 973.11\n",
      "[INFO] total frame elapsed time: 57.98\n",
      "[INFO] queued frames: 128\n",
      "[INFO] frame detection time: 59.62\n",
      "[INFO] accumulated detection time: 1032.73\n",
      "[INFO] total frame elapsed time: 59.71\n",
      "[INFO] queued frames: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\n",
      "    status, run_metadata)\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"<ipython-input-13-e7297bc5ce22>\", line 18, in worker\n",
      "    im, t_elapsed = detect_objects(frame_rgb, sess, detection_graph)\n",
      "  File \"<ipython-input-12-c69ef983c421>\", line 19, in detect_objects\n",
      "    feed_dict={image_tensor: image_np_expanded})\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 889, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/Users/jesperchristensen/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\n",
      "    return fn(*args)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-77f983ebd9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0minput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0moutput_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#output_rgb = cv2.cvtColor(output_q.get(), cv2.COLOR_RGB2BGR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#cv2.imshow('Video', output_rgb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading TF model...\n",
      "[INFO] model loaded...\n"
     ]
    }
   ],
   "source": [
    "num_workers = 1\n",
    "num_queue = 5\n",
    "\n",
    "# debugging\n",
    "#logger = multiprocessing.log_to_stderr()\n",
    "#logger.setLevel(multiprocessing.SUBDEBUG)\n",
    "\n",
    "input_q = Queue(maxsize=num_queue)\n",
    "output_q = Queue(maxsize=num_queue)\n",
    "pool = Pool(num_workers, worker, (input_q, output_q))\n",
    "\n",
    "print(\"[INFO] starting video file thread...\")\n",
    "video_capture = FileVideoStream(\"../data/test_video.mp4\").start()\n",
    "\n",
    "time.sleep(1.0)\n",
    "#video_capture = WebcamVideoStream(src=0,width=480,height=360).start()\n",
    "fps = FPS().start()\n",
    "framecnt = 0\n",
    "while video_capture.more(): \n",
    "    #clear_output(wait=True)\n",
    "    t = time.time()\n",
    "    \n",
    "    frame = video_capture.read()\n",
    "    framecnt = framecnt + 1\n",
    "    frame = imutils.resize(frame, width=480)\n",
    "    input_q.put(frame)\n",
    "\n",
    "    output_rgb = output_q.get()\n",
    "    #output_rgb = cv2.cvtColor(output_q.get(), cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imshow('Video', output_rgb)\n",
    "    #clear_output(wait=True)\n",
    "    #plt.imshow(output_rgb)\n",
    "    #plt.show()\n",
    "    \n",
    "    #if framecnt % 30 == 0:\n",
    "    #    clear_output(wait=True)\n",
    "    #    plt.figure(figsize=(20, 7))\n",
    "    #    plt.imshow(output_rgb)\n",
    "    #    plt.show()\n",
    "    \n",
    "    fps.update()\n",
    "    \n",
    "    print('[INFO] total frame elapsed time: {:.2f}'.format(time.time() - t))\n",
    "    print('[INFO] queued frames: {:d}'.format(video_capture.Q.qsize()))\n",
    "\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "fps.stop()\n",
    "print('[INFO] elapsed time (total): {:.2f}'.format(fps.elapsed()))\n",
    "print('[INFO] approx. FPS: {:.2f}'.format(fps.fps()))\n",
    "print('[INFO] total frames processed: {:d}'.format(framecnt))\n",
    "\n",
    "pool.terminate()\n",
    "video_capture.stop()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS for detection: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('FPS for detection: {:.2f}'.format(framecnt/1032.73))\n",
    "#print('FPS entire processing: {:.2f}'.format(912/fps.elapsed()))\n",
    "#print('Time taken to post-process 31s videofile: {:.2f}s'.format(fps.elapsed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
